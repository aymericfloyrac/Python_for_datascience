{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import wave, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.stats import kurtosis, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###On importe chaque .wav pour le transformer en dataframe puis en indiquant son origine via la variable training\n",
    "zero_a = []\n",
    "zero_a = pd.DataFrame(zero_a)\n",
    "path = '\\\\Python\\\\Projet\\\\training\\\\training-a'\n",
    "for filename in glob.glob(os.path.join(path, '*.wav')):\n",
    "    fs, data = wavfile.read(filename)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.transpose()\n",
    "    zero_a = zero_a.append(df)\n",
    "    del data, fs\n",
    "\n",
    "ref = pd.read_csv('\\\\REFERENCE.csv',sep = ',')\n",
    "#On merge selon l'index car l'ordre est le même\n",
    "base = pd.merge(df, ref, left_index=True, right_index=True)\n",
    "\n",
    "#Export de la base\n",
    "base.to_csv('training-a.csv', index  = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('training-a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('training-a/REFERENCE.csv',header=None,names=['filename','label'])['label']\n",
    "raw_data = dataset.drop(['label'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##ligne perso\n",
    "dataset = pd.read_csv('C:\\\\Users\\\\benoit\\\\Desktop\\\\ENS\\\\ENSAE\\\\2A\\\\S1\\\\Python\\\\Projet\\\\temp\\\\training_a.csv')\n",
    "labels = pd.read_csv('C:\\\\Users\\\\benoit\\\\Desktop\\\\ENS\\\\ENSAE\\\\2A\\\\S1\\\\Python\\\\Projet\\\\training\\\\training-a/REFERENCE.csv',header=None,names=['filename','label'])['label']\n",
    "#raw_data = dataset.drop(['label'],axis=1)\n",
    "raw_data = dataset.drop(['training'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phases_list = ['S1','S2','systole','diastole']\n",
    "features_list = ['t1','t2','t12','t21']\n",
    "phases_peak = [\"S1\",\"S2\"]\n",
    "fea_peak = [\"S1\",\"S2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PCG:\n",
    "    \n",
    "    def __init__(self,signal):\n",
    "        self.signal = np.asarray(signal[~np.isnan(signal)])-np.mean(signal) #on ignore les NaN et on recentre le signal\n",
    "        self.fs = 2000\n",
    "        \n",
    "    def envelogram(self):\n",
    "        E = self.signal\n",
    "        #on remplace les 0 par des petites valeurs (on doit éviter d'avoir un 0 pour calculer les log)\n",
    "        for i in range(self.signal.shape[0]):\n",
    "            if E[i]==0:\n",
    "                E[i] = E[i-1]/10\n",
    "        E = E/np.max(np.abs(E))\n",
    "        #E = E/np.std(E)\n",
    "        E = -1*(E**2) * np.log(E**2)\n",
    "\n",
    "        #on met les petites valeurs à 0 \n",
    "        # il faut d'abord calculer les maximums locaux \n",
    "        window_length = 750\n",
    "        local_max = np.array([np.max(E[i-window_length:i+window_length]) for i in range(window_length,len(E)-window_length)])\n",
    "        local_max = np.concatenate((local_max[0]*np.ones(window_length),local_max,local_max[-1]*np.ones(window_length)))\n",
    "        s = np.std(E)\n",
    "        m = np.mean(E)\n",
    "        mask = E>local_max/5\n",
    "        mask2 = np.abs(E-m)>s/2\n",
    "        mask3 = E>np.mean(E)*2\n",
    "        return E*mask\n",
    "    \n",
    "    \n",
    "    def consec_count(self):\n",
    "        e = self.envelogram()\n",
    "        start = 0\n",
    "        count_mask = []\n",
    "        while  start < len(e): \n",
    "            i = start\n",
    "            current = e[start]\n",
    "            while e[i]==current and i < len(e)-1:\n",
    "                i=i+1\n",
    "            l = int(i - start + 1)\n",
    "            count_mask = np.concatenate((count_mask,l*[l]))\n",
    "            start = i + 1\n",
    "        return count_mask\n",
    "    \n",
    "    def segmentation(self):\n",
    "        E = self.envelogram()\n",
    "        count_vec = self.consec_count() # le vecteur de comptage associé\n",
    "        length_threshold = 50\n",
    "        beat_mask = count_vec<=length_threshold\n",
    "        systole_mask = count_vec>length_threshold\n",
    "        segmentation = np.asarray([])\n",
    "        mean_beat_length = 0\n",
    "        beat_counter = 0\n",
    "        i = 0\n",
    "        splits = []\n",
    "        while i<count_vec.shape[0]:\n",
    "            stop = i \n",
    "            next_stop = i\n",
    "            while stop < count_vec.shape[0] and next_stop-stop<0.100*self.fs:\n",
    "                stop = next_stop\n",
    "                #on calcule la longueur du pic\n",
    "                while stop<count_vec.shape[0] and beat_mask[stop]:\n",
    "                    stop+=1\n",
    "\n",
    "                #on calcule l'écart avec le pic suivant, pour voir s'il s'agit du même pic\n",
    "                next_stop = stop\n",
    "                while next_stop<count_vec.shape[0] and not beat_mask[next_stop]:\n",
    "                    next_stop +=1\n",
    "                \n",
    "            #un battement long est un battement S1\n",
    "            if stop-i>mean_beat_length:\n",
    "                segmentation = np.concatenate((segmentation,np.repeat('S1',stop-i)))\n",
    "                current_seq = {'beat':'S1','passive':'systole'}\n",
    "                \n",
    "            #un battement court est un battement S2\n",
    "            else:\n",
    "                segmentation = np.concatenate((segmentation,np.repeat('S2',stop-i)))\n",
    "                current_seq = {'beat':'S2','passive':'diastole'}\n",
    "                \n",
    "            #update beat length and parser\n",
    "            mean_beat_length = np.average([stop-i,mean_beat_length],weights=[1,beat_counter])\n",
    "            beat_counter += 1\n",
    "            i = stop\n",
    "                \n",
    "            while stop<count_vec.shape[0] and systole_mask[stop]:\n",
    "                stop+=1\n",
    "                \n",
    "            segmentation = np.concatenate((segmentation,np.repeat(current_seq['passive'],stop-i)))\n",
    "            #update parser\n",
    "            i = stop\n",
    "        \n",
    "        #on supprime tout ce qui est avant la première phase S1: \n",
    "        j = 0 \n",
    "        while segmentation[j]!='S1':\n",
    "            j += 1\n",
    "            \n",
    "        return segmentation[j:],E[j:],j\n",
    "    \n",
    "    \n",
    "    def timeLengths(self,segmentation,phase):\n",
    "        res=[]\n",
    "        start=0\n",
    "        while start<segmentation.shape[0]:\n",
    "            i = start\n",
    "            while i<segmentation.shape[0] and segmentation[i]==phase:\n",
    "                i+=1\n",
    "            res.append(i - start)\n",
    "            start = i + 1\n",
    "        res = np.array(res)\n",
    "        return np.array(res[res!=0])\n",
    "    \n",
    "    def beatLengths(self,segmentation):\n",
    "        res = []\n",
    "        start = 0\n",
    "        bound = len(segmentation)\n",
    "        #on commence sur la première phase S1\n",
    "        while segmentation[start]!='S1':\n",
    "            start+=1\n",
    "        #on parcourt toute la segmentation\n",
    "        while start<bound:\n",
    "            explorer = start\n",
    "            while explorer < bound and segmentation[explorer]=='S1':#on finit la phase S1\n",
    "                explorer += 1\n",
    "            while explorer < bound and segmentation[explorer]!='S1': #on va jusqu'à la phase S1 suivante\n",
    "                explorer+=1\n",
    "            res.append(explorer-start)\n",
    "            start = explorer\n",
    "        return np.array(res)\n",
    "    \n",
    "    def extractFeatures(self):\n",
    "        segmentation, E, reste = self.segmentation()\n",
    "        features = np.array([])\n",
    "        beat_lengths = self.beatLengths(segmentation)\n",
    "        #time features\n",
    "        for phase in phases_list:\n",
    "            time_features = self.timeLengths(segmentation,phase)\n",
    "            if phase=='systole' or phase=='diastole':\n",
    "                if time_features.shape==beat_lengths.shape:\n",
    "                    ratio = time_features/beatLengths\n",
    "                else: \n",
    "                    time_features = time_features[:-beat_lengths.shape[0]] #on resynchronise, normalement au + 1d'écart\n",
    "            features = np.append(features,[np.mean(time_features),np.std(time_features)])\n",
    "        \n",
    "        \n",
    "            \n",
    "        #peak features    \n",
    "        p_S1 = []\n",
    "        p_S2 = []\n",
    "        borne = []\n",
    "        \n",
    "        for i in range(len(segmentation)-1):\n",
    "            if segmentation[i-1] != segmentation[i]:\n",
    "                borne.append(i)\n",
    "        for i in range(0,len(borne)-1):\n",
    "            if segmentation[borne[i]] == 'S1':\n",
    "                peaks, _ = find_peaks(E[borne[i]:borne[i+1]],height=0,distance = borne[i+1])\n",
    "                if len(peaks) != 0:\n",
    "                    index = borne[i] + peaks[0]\n",
    "                    p_S1.append(E[index])    \n",
    "            if segmentation[borne[i]] == 'S2':\n",
    "                peaks, _ = find_peaks(E[borne[i]:borne[i+1]],height=0,distance = borne[i+1])\n",
    "                if len(peaks) != 0:\n",
    "                    index = borne[i] + peaks[0]\n",
    "                    p_S2.append(E[index])\n",
    "\n",
    "        features = np.append(features,[np.mean(p_S1),np.min(p_S1),np.max(p_S1),np.std(p_S1)])\n",
    "        features = np.append(features,[np.mean(p_S2),np.min(p_S2),np.max(p_S2),np.std(p_S2)])\n",
    "        \n",
    "        #Skewness et Kurtosis\n",
    "        skew_S1 = []\n",
    "        skew_S2 = []\n",
    "        skew_sys = []\n",
    "        skew_dis = []\n",
    "        kur_S1 = []\n",
    "        kur_S2 = []\n",
    "        kur_sys = []\n",
    "        kur_dis = []\n",
    "        \n",
    "        for i in range(0,len(borne)-1):\n",
    "            if segmentation[borne[i]] == 'S1':\n",
    "                skew1 = skew(E[borne[i]:borne[i+1]])\n",
    "                skew_S1.append(skew1)    \n",
    "            if segmentation[borne[i]] == 'S2':\n",
    "                skew2 = skew(E[borne[i]:borne[i+1]])\n",
    "                skew_S2.append(skew2) \n",
    "            if segmentation[borne[i]] == 'diastole':\n",
    "                skewdis = skew(E[borne[i]:borne[i+1]])\n",
    "                skew_dis.append(skew_dis) \n",
    "            if segmentation[borne[i]] == 'systole':\n",
    "                skewsys = skew(E[borne[i]:borne[i+1]])\n",
    "                skew_sys.append(skewsys) \n",
    "\n",
    "        for i in range(0,len(borne)-1):\n",
    "            if segmentation[borne[i]] == 'S1':\n",
    "                kur1 = kurtosis(E[borne[i]:borne[i+1]])\n",
    "                kur_S1.append(kur1)    \n",
    "            if segmentation[borne[i]] == 'S2':\n",
    "                kur2 = kurtosis(E[borne[i]:borne[i+1]])\n",
    "                kur_S2.append(kur2) \n",
    "            if segmentation[borne[i]] == 'diastole':\n",
    "                kurdis = kurtosis(E[borne[i]:borne[i+1]])\n",
    "                kur_dis.append(kurdis) \n",
    "            if segmentation[borne[i]] == 'systole':\n",
    "                kursys = kurtosis(E[borne[i]:borne[i+1]])\n",
    "                kur_sys.append(kursys) \n",
    "\n",
    "        features = np.append(features,[np.mean(skew_S1),np.min(skew_S1),np.max(skew_S1),np.std(skew_S1)])\n",
    "        features = np.append(features,[np.mean(skew_S2),np.min(skew_S2),np.max(kur_S2),np.std(skew_S2)])\n",
    "        features = np.append(features,[np.mean(0),np.min(0),np.max(0),np.std(0)])\n",
    "        features = np.append(features,[np.mean(0),np.min(0),np.max(0),np.std(0)])\n",
    "        \n",
    "        features = np.append(features,[np.mean(kur_S1),np.min(kur_S1),np.max(kur_S1),np.std(kur_S1)])\n",
    "        features = np.append(features,[np.mean(kur_S2),np.min(kur_S2),np.max(kur_S2),np.std(kur_S2)])\n",
    "        features = np.append(features,[np.mean(0),np.min(0),np.max(0),np.std(0)])\n",
    "        features = np.append(features,[np.mean(0),np.min(0),np.max(0),np.std(0)])\n",
    "        \n",
    "        #mean12 feature\n",
    "        features = np.append(features,max(features[8],features[12]))\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_length = 10000\n",
    "sample = raw_data.loc[0][:time_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['S1', 'S1', 'S1', ..., 'systole', 'systole', 'systole'],\n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcg = PCG(sample)\n",
    "segmentation = pcg.segmentation()[0]\n",
    "segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( 'excess kurtosis of normal distribution (should be 0): {}'.format( kurtosis(E) ))\n",
    "print( 'skewness of normal distribution (should be 0): {}'.format( skew(E) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PCG' object has no attribute 'setStart'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-53e470a5ebed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpcg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetStart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpcg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvelogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_length\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_between\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhere\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'S1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'S1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCG' object has no attribute 'setStart'"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "E,lag = pcg.setStart(pcg.envelogram())\n",
    "l = time_length-lag\n",
    "x = np.linspace(0,l/2000,l)\n",
    "plt.fill_between(x,0,1,where = segmentation=='S1',facecolor='r',alpha=.3,label='S1')\n",
    "plt.fill_between(x,0,1,where = segmentation=='S2',facecolor='r',alpha=.1,label='S2')\n",
    "plt.fill_between(x,0,1,where = segmentation=='systole',facecolor='b',alpha=.3,label='systole')\n",
    "plt.fill_between(x,0,1,where = segmentation=='diastole',facecolor='b',alpha=.1,label='diastole')\n",
    "\n",
    "plt.plot(x,E/np.max(E),'k',label='signal')\n",
    "plt.legend()\n",
    "plt.xlabel('temps (s)')\n",
    "plt.ylabel('amplitude normalisée')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = raw_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "t1,t2,t12,t21=[],[],[],[]\n",
    "for i in range(n_samples):\n",
    "    try:\n",
    "        pcg = PCG(raw_data.loc[i])\n",
    "        ft = pcg.extractFeatures()\n",
    "        t1.append(ft['t1'][0])\n",
    "        t2.append(ft['t2'][0])\n",
    "        t12.append(ft['t12'][0])\n",
    "        t21.append(ft['t21'][0])\n",
    "    except: \n",
    "        print(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convertion en Df au cas où\n",
    "X = np.column_stack((t1,t2,t12,t21,m12,ps1,ps2,good))\n",
    "X_df = pd.DataFrame(X, columns=[\"t1\",\"t2\",\"t12\",\"t21\",\"mean12\",\"S1\",\"S2\",\"Normal\"])\n",
    "X_df[\"Normal\"] = X_df[\"Normal\"].map({0 : \"anormal\", 1 : \"normal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Normal \n",
       "S1   count  anormal     29.000000\n",
       "            normal      71.000000\n",
       "     mean   anormal      0.294212\n",
       "            normal       0.267189\n",
       "     std    anormal      0.068271\n",
       "            normal       0.079283\n",
       "     min    anormal      0.095483\n",
       "            normal       0.033162\n",
       "     25%    anormal      0.249395\n",
       "            normal       0.241749\n",
       "     50%    anormal      0.317319\n",
       "            normal       0.283967\n",
       "     75%    anormal      0.348103\n",
       "            normal       0.322913\n",
       "     max    anormal      0.365195\n",
       "            normal       0.367295\n",
       "S2   count  anormal     29.000000\n",
       "            normal      71.000000\n",
       "     mean   anormal      0.159638\n",
       "            normal       0.134995\n",
       "     std    anormal      0.048082\n",
       "            normal       0.053529\n",
       "     min    anormal      0.094925\n",
       "            normal       0.016176\n",
       "     25%    anormal      0.121570\n",
       "            normal       0.096942\n",
       "     50%    anormal      0.146255\n",
       "            normal       0.130643\n",
       "     75%    anormal      0.197100\n",
       "            normal       0.165587\n",
       "                          ...    \n",
       "t2   mean   anormal     30.593501\n",
       "            normal      33.319522\n",
       "     std    anormal     10.552384\n",
       "            normal      27.281276\n",
       "     min    anormal     15.342857\n",
       "            normal      10.125000\n",
       "     25%    anormal     23.810427\n",
       "            normal      20.718995\n",
       "     50%    anormal     28.050000\n",
       "            normal      26.163636\n",
       "     75%    anormal     34.666667\n",
       "            normal      38.040000\n",
       "     max    anormal     54.772727\n",
       "            normal     210.859649\n",
       "t21  count  anormal     29.000000\n",
       "            normal      71.000000\n",
       "     mean   anormal    401.953336\n",
       "            normal     357.021347\n",
       "     std    anormal    191.935409\n",
       "            normal     168.788948\n",
       "     min    anormal    129.197970\n",
       "            normal      69.070175\n",
       "     25%    anormal    295.575472\n",
       "            normal     235.401786\n",
       "     50%    anormal    387.938462\n",
       "            normal     323.138462\n",
       "     75%    anormal    473.593750\n",
       "            normal     472.135931\n",
       "     max    anormal    865.714286\n",
       "            normal     771.840000\n",
       "Length: 112, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taleau descriptif\n",
    "X_df.groupby([\"Normal\"]).describe().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x23e06f10470>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrice de corrélation\n",
    "sns.heatmap(X_df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benoit\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:637: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  kde_data = remove_na(group_data[hue_mask])\n",
      "C:\\Users\\benoit\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:885: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  violin_data = remove_na(group_data[hue_mask])\n",
      "C:\\Users\\benoit\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:905: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  violin_data = remove_na(group_data)\n"
     ]
    }
   ],
   "source": [
    "#Violin plot per variable\n",
    "features_list = X_df.columns[:-1]\n",
    "for i in features_list:\n",
    "    fig = plt.figure()\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    ax = sns.violinplot(x = [i]*len(X_df), y=X_df[i],hue=X_df[\"Normal\"], palette=\"Set2\", split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good = labels[:n_samples]==1\n",
    "bad = labels[:n_samples]==-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-4449949b6458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m221\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#t = t\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0max1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbad\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'anormal'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not Series"
     ]
    }
   ],
   "source": [
    "#Histogrammes par variable\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "ax1 = fig.add_subplot(221)\n",
    "#t = t\n",
    "ax1.hist(t1[good],normed=True,color='b',label='normal',alpha=.5)\n",
    "t = t1[bad]\n",
    "ax1.hist(t1[bad],normed=True,color='r',label='anormal',alpha=.5)\n",
    "ax1.set_title('t1')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "t = t2[good]\n",
    "ax2.hist(t2[good],normed=True,color='b',label='normal',alpha=.5)\n",
    "t = t2[bad]\n",
    "ax2.hist(t2[bad],normed=True,color='r',label='anormal',alpha=.5)\n",
    "ax2.set_title('t2')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.hist(t12[good],normed=True,color='b',label='normal',alpha=.5)\n",
    "ax3.hist(t12[bad],normed=True,color='r',label='anormal',alpha=.5)\n",
    "ax3.set_title('t12')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "ax4.hist(t21[good],normed=True,color='b',label='normal',alpha=.5)\n",
    "ax4.hist(t21[bad],normed=True,color='r',label='anormal',alpha=.5)\n",
    "ax4.set_title('t21')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benoit\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 7)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.column_stack((t1,t2,t12,t21,ps1,ps2,m12))\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_=y = X_df.loc[:,\"Normal\"].values\n",
    "labels_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#Logit\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_, test_size=0.20)\n",
    "logit = LogisticRegression()\n",
    "result = logit.fit(X_train, y_train)\n",
    "predictions = logit.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_, test_size=0.20)\n",
    "RF =  RandomForestClassifier(n_estimators=150, max_depth=7, random_state=0)\n",
    "result = RF.fit(X_train, y_train)\n",
    "predictions = RF.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels_, test_size=0.20)\n",
    "clf = SVC()\n",
    "result = clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70588235 0.70588235 0.71875   ]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "print(cross_val_score(svm,features,labels_,cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'n_estimators': 100}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF\n",
    "param_grid = {'n_estimators': [100, 150, 200, 250, 300],'max_depth': [2, 4, 6, 7]}\n",
    "grid_RF = GridSearchCV(RF, param_grid, cv=10)\n",
    "grid_RF.fit(X_train, y_train)\n",
    "grid_RF. best_estimator_\n",
    "grid_RF. best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-2-02156ae22fd6>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-02156ae22fd6>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,'precision')\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#Pour un SVM\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4, 1e-5, 1e-6],'C': [1, 10, 100, 1000]}]\n",
    "print(\"# Tuning hyper-parameters for %s\" % 'precision')\n",
    "print()\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-78df22177a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
